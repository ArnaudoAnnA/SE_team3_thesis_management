RETROSPECTIVE 1 (Team 3)
=====================================

The retrospective should include _at least_ the following
sections:

- [process measures](#process-measures)
- [quality measures](#quality-measures)
- [general assessment](#assessment)

## PROCESS MEASURES 

### Macro statistics

- Number of stories committed vs. done

 3/5

- Total points committed vs. done

10/14

- Nr of hours planned vs. spent (as a team)

92h 15m / 110h 30m

**Remember** a story is done ONLY if it fits the Definition of Done:
 
- Unit Tests passing
- Manual FE testing
- Code review completed
- Code present on VCS
- End-to-End tests performed

> Please refine your DoD if required (you cannot remove items!) 

### Detailed statistics

| Story  | # Tasks | Points | Hours est. | Hours actual |
|--------|---------|--------|------------|--------------|
| _#0_   |     13   |    -   |   49h 45m    |   52h   |
| _#1_   |     4   |    3   |     12h 30m    |   15h 20m   |
| _#2_   |    6    |    5   |     22h    |   33h 50m        |
| _#3_   |    4    |    2   |     8h    |      9h 40m     |

- _#0_ corresponds to initial setups and meetings
- _#1_ : Insert proposal
- _#2_ : Search proposal
- _#3_ : Apply for proposal

> place technical tasks corresponding to story `#0` and leave out story points (not applicable in this case)

- Estimated Hours per task average: 3h 25m
- Actual Hours per task average: 4h 05m
- Estimated Hours Standard deviation: to calculate
- Actual Hours Standard deviation: to calculate

- Total task estimation error ratio [(sum of total hours estimation / sum of total hours spent) - 1]: 5535m / 6630 = |-0,165| = 16%

  
## QUALITY MEASURES 

- Unit Testing:
  - Total hours estimated: 
  - Total hours spent: 
  - Nr of automated unit test cases: 
  - Coverage (if available):
- E2E testing:
  - Total hours estimated: 
  - Total hours spent: 
- Code review 
  - Total hours estimated: 
  - Total hours spent: 
  


## ASSESSMENT

- What caused your errors in estimation (if any)?

We understimated the learning curve for Firebase and the use of several JS libraries.
We also understimated the time needed for coordinating front end teams and back end ones.


- What lessons did you learn (both positive and negative) in this sprint?

First lesson: we have to improve our definition of interfaces between front end and back end;
Second lesson: we need more comunication and more team work during developing.


- Which improvement goals set in the previous retrospective were you able to achieve? 

In previous retrospecive we fixed two things to be improved, and we managed to achieve bot goals (throught their are still to be further improved):
1. manage tests (in particolar manual tests) with more attention;
2. define in a more detailed way the roles in the team (= who is in charge of what).

  
- Which ones you were not able to achieve? Why?

We have still to improve our managing of manual testing.


- Improvement goals for the next sprint and how to achieve them (technical tasks, team coordination, etc.)

1. have a meeting between peoples in charge of the same story before starting developing (1h30 it's enough): the objective is pre-defining the interfaces, methods and APIs' signatures;
2. establish a deadline inside the sprint and try to have the code ready for that date, so then we can focus on testing;
3. Manual drawing of GUI before starting developing.

- One thing you are proud of as a Team!!

Even if we have incountered several obstacles in this sprint, we never argued: we helped each other to reach the finale goal.